{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TmJEFmRKh57"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ne4jfBmRaSxJ",
        "outputId": "1c969a36-5cbe-4a4f-bde3-ccd6b854e083"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.14)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.1)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ciHh-umKks3",
        "outputId": "880b74c4-859e-4a21-a54a-8ca41c2e7831"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.11/dist-packages (1.2.8)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.14.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (8.5.0)\n",
            "Requirement already satisfied: scipy==1.14.0 in /usr/local/lib/python3.11/dist-packages (1.14.0)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy==1.14.0) (2.0.2)\n",
            "Collecting optuna\n",
            "  Using cached optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Using cached alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Using cached colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n",
            "Using cached optuna-4.4.0-py3-none-any.whl (395 kB)\n",
            "Using cached alembic-1.16.2-py3-none-any.whl (242 kB)\n",
            "Using cached colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: colorlog, alembic, optuna\n",
            "Successfully installed alembic-1.16.2 colorlog-6.9.0 optuna-4.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost\n",
        "!pip install scipy==1.14.0\n",
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0wL_tP4lKZVk"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import scipy\n",
        "from scipy.optimize import nnls\n",
        "from scipy.optimize import lsq_linear\n",
        "\n",
        "import ast\n",
        "\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import optuna\n",
        "\n",
        "from catboost import CatBoostRegressor, Pool\n",
        "from sklearn.metrics import mean_absolute_error, explained_variance_score, mean_absolute_percentage_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZa30VAiW9NT"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.width', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvikV0esK6d4"
      },
      "source": [
        "## Data\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe5aKiR_K7vi",
        "outputId": "8788069c-459e-429e-af8f-1fcc154fc9e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWgPb3cBK-AZ"
      },
      "outputs": [],
      "source": [
        "vacancies = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/cost_of_skills/IT_vacancies_full.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F6CqEwjzNXUh"
      },
      "outputs": [],
      "source": [
        "# Applying the logic\n",
        "vacancies['To'] = vacancies.apply(lambda row: row['From'] if pd.isna(row['To']) and not pd.isna(row['From']) and row['To'] != 0 else row['To'], axis=1)\n",
        "vacancies['From'] = vacancies.apply(lambda row: row['To'] - 10000 if pd.isna(row['From']) and not pd.isna(row['To']) and row['To'] != 0 else row['From'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PZoSpAcbbb-0"
      },
      "outputs": [],
      "source": [
        "vacancies = vacancies.rename(columns={'Keys': 'Skills'})\n",
        "vacancies['Skills'] = vacancies['Skills'].apply(lambda x: ast.literal_eval(x))\n",
        "vacancies['Profarea names'] = vacancies['Profarea names'].apply(lambda x: eval(x))\n",
        "vacancies['Professional roles'] = vacancies['Professional roles'].apply(lambda x: eval(x))\n",
        "\n",
        "vacancies['Specializations'] = vacancies['Specializations'].apply(lambda x: eval(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qhSgiYuD49M"
      },
      "outputs": [],
      "source": [
        "# Applying the logic\n",
        "vacancies['To'] = vacancies.apply(lambda row: row['From'] if pd.isna(row['To']) and not pd.isna(row['From']) and row['To'] != 0 else row['To'], axis=1)\n",
        "vacancies['From'] = vacancies.apply(lambda row: row['To'] - 10000 if pd.isna(row['From']) and not pd.isna(row['To']) and row['To'] != 0 else row['From'], axis=1)\n",
        "\n",
        "# Dropping rows where both From and To are NaN\n",
        "vacancies.dropna(subset=['From', 'To'], how='all', inplace=True)\n",
        "\n",
        "vacancies = vacancies[vacancies['To'] != 0]\n",
        "\n",
        "#vacancies['Profarea names'] = vacancies['Profarea names'].apply(lambda x: eval(x))\n",
        "vacancies = vacancies[vacancies['Salary'] == True]\n",
        "vacancies = vacancies.drop('Salary', axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4_5GpmqQNIcb"
      },
      "outputs": [],
      "source": [
        "vacancies = vacancies.reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NeAUy_7bScL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stat"
      ],
      "metadata": {
        "id": "irV2pFMuIYhV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_skill_dict(vacancies, prof_areas):\n",
        "    \"\"\"\n",
        "    Функция пробегается по каждому названию области,\n",
        "    обучает модель (получаем вектор x) и формирует итоговый словарь.\n",
        "    \"\"\"\n",
        "    skill_dict = {}\n",
        "\n",
        "    for area in prof_areas:\n",
        "        # 1. Фильтруем вакансии, относящиеся к выбранной области\n",
        "        data = vacancies[\n",
        "            vacancies['Profarea names'].apply(\n",
        "                lambda prof_list: any(area in prof for prof in prof_list)\n",
        "            )\n",
        "        ].copy().dropna().reset_index(drop=True)\n",
        "\n",
        "        # 2. Минимальная предобработка (как в вашем коде):\n",
        "        data = data[['Skills', 'From', 'To']].rename(columns={'From': 'from', 'To': 'to'})\n",
        "        # Убираем строки, где from == to\n",
        "        data = data[data['from'] != data['to']]\n",
        "        # Убираем строки, где Skills пуст\n",
        "        data = data[data['Skills'].apply(len) > 0]\n",
        "\n",
        "        if len(data) == 0:\n",
        "            # Если для этой области данных нет, создаём пустой словарь\n",
        "            skill_dict[area] = {}\n",
        "            continue\n",
        "\n",
        "        # 3. Собираем список всех навыков\n",
        "        all_skills = get_all_skills(data)\n",
        "\n",
        "        # 4. Создаём словарь маппинга навыка -> индекс\n",
        "        skill_id_dict = {skill: idx for idx, skill in enumerate(all_skills)}\n",
        "\n",
        "        # 5. Собираем матрицу A\n",
        "        A = get_matrix(data, skill_id_dict)\n",
        "        A_torch = torch.tensor(A, dtype=torch.float32, device=device)\n",
        "\n",
        "        U, S, Vh = torch.linalg.svd(A_torch, full_matrices=False)\n",
        "\n",
        "        # Максимальное сингулярное число\n",
        "        max_singular_value = torch.max(S)\n",
        "\n",
        "        print(f\"Специальность: {area} : {A_torch.shape[0]}, {A_torch.shape[1]}, собственные числа: {max_singular_value}\")\n"
      ],
      "metadata": {
        "id": "8YkDPQHBIafW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(prof_areas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_R0DpuJdI97e",
        "outputId": "dac6a0af-b8ef-4853-c8d0-5d8302d47455"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "build_skill_dict(vacancies, prof_areas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qEasJrMAJglA",
        "outputId": "a9f5acac-8fb1-4721-b406-3eb5747c86fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Специальность: Государственная служба, некоммерческие организации : 24, 118, собственные числа: 6.262829303741455\n",
            "Специальность: Туризм, гостиницы, рестораны : 16, 84, собственные числа: 4.5614705085754395\n",
            "Специальность: Рабочий персонал : 314, 560, собственные числа: 13.550824165344238\n",
            "Специальность: Информационные технологии, интернет, телеком : 8049, 5184, собственные числа: 51.4238395690918\n",
            "Специальность: Безопасность : 74, 210, собственные числа: 7.137026786804199\n",
            "Специальность: Бухгалтерия, управленческий учет, финансы предприятия : 68, 246, собственные числа: 6.59346342086792\n",
            "Специальность: Продажи : 603, 834, собственные числа: 29.56612205505371\n",
            "Специальность: Медицина, фармацевтика : 37, 163, собственные числа: 7.3853840827941895\n",
            "Специальность: Искусство, развлечения, масс-медиа : 305, 591, собственные числа: 16.22970199584961\n",
            "Специальность: Начало карьеры, студенты : 262, 676, собственные числа: 16.421289443969727\n",
            "Специальность: Добыча сырья : 14, 73, собственные числа: 3.9641273021698\n",
            "Специальность: Домашний персонал : 2, 11, собственные числа: 2.4494893550872803\n",
            "Специальность: Высший менеджмент : 99, 378, собственные числа: 11.822296142578125\n",
            "Специальность: Производство, сельское хозяйство : 223, 583, собственные числа: 8.27175521850586\n",
            "Специальность: Управление персоналом, тренинги : 54, 282, собственные числа: 7.830305099487305\n",
            "Специальность: Консультирование : 393, 858, собственные числа: 16.383073806762695\n",
            "Специальность: Юристы : 5, 24, собственные числа: 2.8573150634765625\n",
            "Специальность: Инсталляция и сервис : 397, 761, собственные числа: 14.378039360046387\n",
            "Специальность: Строительство, недвижимость : 187, 518, собственные числа: 10.133283615112305\n",
            "Специальность: Автомобильный бизнес : 20, 90, собственные числа: 5.405355930328369\n",
            "Специальность: Банки, инвестиции, лизинг : 140, 471, собственные числа: 11.481793403625488\n",
            "Специальность: Маркетинг, реклама, PR : 889, 1272, собственные числа: 22.2606258392334\n",
            "Специальность: Закупки : 28, 154, собственные числа: 5.958078384399414\n",
            "Специальность: Спортивные клубы, фитнес, салоны красоты : 19, 74, собственные числа: 7.152817726135254\n",
            "Специальность: Транспорт, логистика : 50, 213, собственные числа: 6.141029357910156\n",
            "Специальность: Страхование : 6, 45, собственные числа: 4.752526760101318\n",
            "Специальность: Административный персонал : 181, 441, собственные числа: 14.748804092407227\n",
            "Специальность: Наука, образование : 75, 340, собственные числа: 7.3476338386535645\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for area in prof_areas:\n",
        "  data = vacancies[\n",
        "            vacancies['Profarea names'].apply(\n",
        "                lambda prof_list: any(area in prof for prof in prof_list)\n",
        "            )\n",
        "        ].copy().dropna().reset_index(drop=True)\n",
        "\n",
        "  print(f\"Специальность: {area} : {len(data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DH38pYLIjNP",
        "outputId": "72c553f1-b00f-4146-fa76-ac546b3ac8d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Специальность: Государственная служба, некоммерческие организации : 69\n",
            "Специальность: Туризм, гостиницы, рестораны : 38\n",
            "Специальность: Рабочий персонал : 885\n",
            "Специальность: Информационные технологии, интернет, телеком : 17580\n",
            "Специальность: Безопасность : 211\n",
            "Специальность: Бухгалтерия, управленческий учет, финансы предприятия : 152\n",
            "Специальность: Продажи : 1576\n",
            "Специальность: Медицина, фармацевтика : 107\n",
            "Специальность: Искусство, развлечения, масс-медиа : 629\n",
            "Специальность: Начало карьеры, студенты : 739\n",
            "Специальность: Добыча сырья : 28\n",
            "Специальность: Домашний персонал : 13\n",
            "Специальность: Высший менеджмент : 230\n",
            "Специальность: Производство, сельское хозяйство : 693\n",
            "Специальность: Управление персоналом, тренинги : 111\n",
            "Специальность: Консультирование : 918\n",
            "Специальность: Юристы : 13\n",
            "Специальность: Инсталляция и сервис : 998\n",
            "Специальность: Строительство, недвижимость : 446\n",
            "Специальность: Автомобильный бизнес : 48\n",
            "Специальность: Банки, инвестиции, лизинг : 284\n",
            "Специальность: Маркетинг, реклама, PR : 1975\n",
            "Специальность: Закупки : 70\n",
            "Специальность: Спортивные клубы, фитнес, салоны красоты : 48\n",
            "Специальность: Транспорт, логистика : 112\n",
            "Специальность: Страхование : 25\n",
            "Специальность: Административный персонал : 583\n",
            "Специальность: Наука, образование : 215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wr2tCUeDVaLi"
      },
      "source": [
        "## Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqhHvyOrC9S7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "################################################################################\n",
        "# Обработка датафрейма и построение матрицы навыков\n",
        "################################################################################\n",
        "\n",
        "def get_all_skills(data: pd.DataFrame) -> list:\n",
        "    \"\"\"\n",
        "    Собирает все уникальные навыки из столбца 'Skills' (список навыков в каждой строке).\n",
        "    Возвращает список навыков (строки в нижнем регистре).\n",
        "    \"\"\"\n",
        "    all_skills = []\n",
        "    for row in data['Skills']:\n",
        "        # row - это список навыков для строки датафрейма\n",
        "        lowercase_list = [item.lower() for item in row]\n",
        "        all_skills.extend(lowercase_list)\n",
        "\n",
        "    return list(set(all_skills))\n",
        "\n",
        "\n",
        "def make_cf(indices: list, skill_amount: int) -> list:\n",
        "    \"\"\"\n",
        "    Создаёт вектор признаков для одной строки датафрейма.\n",
        "    Напр. если у строки навыки: [0, 3, 5], а всего навыков skill_amount=10,\n",
        "    то возвращаем вектор длины 10, где на позициях (0,3,5) будет 1, остальные 0.\n",
        "    \"\"\"\n",
        "    cf = [0]*skill_amount\n",
        "    for i in indices:\n",
        "        cf[i] = 1\n",
        "    return cf\n",
        "\n",
        "\n",
        "def get_matrix(data: pd.DataFrame, skill_id_dict: dict) -> list:\n",
        "    \"\"\"\n",
        "    Строит матрицу A размера [num_rows x skill_amount],\n",
        "    где num_rows = число строк в data.\n",
        "    \"\"\"\n",
        "    skill_amount = len(skill_id_dict)\n",
        "    A = []\n",
        "    for row in data['Skills']:\n",
        "        # Преобразуем навыки строки в индексы\n",
        "        indices = [skill_id_dict[skill.lower()] for skill in row]\n",
        "        A.append(make_cf(indices, skill_amount))\n",
        "    return A\n",
        "\n",
        "\n",
        "################################################################################\n",
        "# Основная PyTorch-функция, которая оптимизирует интервальный лосс\n",
        "################################################################################\n",
        "\n",
        "torch.manual_seed(42)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(42)\n",
        "    torch.cuda.manual_seed_all(42)\n",
        "\n",
        "def calc_torch_interval(A, from_col, to_col, lr=5.0, num_iterations=10000):\n",
        "    \"\"\"\n",
        "    A: матрица признаков (list of lists или numpy), размер [N x M].\n",
        "    from_col: список или массив c нижней границей зарплаты (длина N).\n",
        "    to_col: список или массив c верхней границей зарплаты (длина N).\n",
        "    lr: learning rate.\n",
        "    num_iterations: количество итераций для оптимизации.\n",
        "\n",
        "    Возвращает:\n",
        "      - x: тензор PyTorch (веса навыков),\n",
        "      - final_interval_loss: скаляр (итоговый интервальный лосс),\n",
        "      - mae: скаляр (MAE относительно середины интервала).\n",
        "    \"\"\"\n",
        "    # Переводим A и интервалы из Python-списков/NumPy-массивов в PyTorch-тензоры\n",
        "    A_torch = torch.tensor(A, dtype=torch.float32, device=device)\n",
        "    from_torch = torch.tensor(from_col, dtype=torch.float32, device=device)\n",
        "    to_torch = torch.tensor(to_col, dtype=torch.float32, device=device)\n",
        "\n",
        "    # Параметры модели: вектор x размером M (число навыков)\n",
        "    # Инициализируем значением: 10000 + случайное число от 0 до 1000 чтобы убрать однаковые значения в x\n",
        "    random_values = 10000 + 1000 * torch.rand((A_torch.shape[1]))\n",
        "    random_v = random_values.to(device)\n",
        "    x = torch.nn.Parameter(random_v)\n",
        "\n",
        "    optimizer = torch.optim.Adam([x], lr=lr)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer, mode='min', factor=0.9, patience=500, verbose=False\n",
        "    )\n",
        "\n",
        "    for iteration in range(num_iterations):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Предсказанная зарплата для каждой строки: y_pred = A*x\n",
        "        y_pred = A_torch.matmul(x)\n",
        "\n",
        "        # Интервальный лосс:\n",
        "        # loss = среднее (max(0, from_i - y_pred_i) + max(0, y_pred_i - to_i))\n",
        "        under = torch.clamp(from_torch - y_pred, min=0.0)  # штраф, если y_pred < from\n",
        "        over  = torch.clamp(y_pred - to_torch, min=0.0)    # штраф, если y_pred > to\n",
        "        interval_loss = torch.mean(under + over)\n",
        "\n",
        "        #print(f\"Loss {interval_loss}\")\n",
        "\n",
        "        interval_loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step(interval_loss)\n",
        "\n",
        "    # После обучения считаем финальные предсказания\n",
        "    y_pred_final = A_torch.matmul(x)\n",
        "\n",
        "    # Финальный интервальный лосс\n",
        "    final_interval_loss = interval_loss.detach().cpu().item()\n",
        "\n",
        "    # Средняя точка интервала для каждой строки\n",
        "    mid_interval = 0.5 * (from_torch + to_torch)\n",
        "\n",
        "    # MAE относительно средней точки [from, to]\n",
        "    mae = torch.mean(torch.abs(y_pred_final - mid_interval)).detach().cpu().item()\n",
        "\n",
        "    return x, final_interval_loss, mae\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test of all data"
      ],
      "metadata": {
        "id": "s-qpc_NUAz0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#собираем все Profarea names\n",
        "prof_lst = []\n",
        "for i in vacancies['Profarea names']:\n",
        "    prof_lst += i\n",
        "prof_dict = {i: [] for i in set(prof_lst)}\n",
        "\n",
        "for i, j in enumerate(vacancies['Profarea names']):\n",
        "    for k in j:\n",
        "        prof_dict[k].append(i)\n",
        "\n",
        "prof_areas = list(prof_dict.keys())"
      ],
      "metadata": {
        "id": "DHUccjaulaeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_skill_dict(vacancies, prof_areas):\n",
        "    \"\"\"\n",
        "    Функция пробегается по каждому названию области,\n",
        "    обучает модель (получаем вектор x) и формирует итоговый словарь.\n",
        "    \"\"\"\n",
        "    skill_dict = {}\n",
        "\n",
        "    for area in prof_areas:\n",
        "        # 1. Фильтруем вакансии, относящиеся к выбранной области\n",
        "        data = vacancies[\n",
        "            vacancies['Profarea names'].apply(\n",
        "                lambda prof_list: any(area in prof for prof in prof_list)\n",
        "            )\n",
        "        ].copy().dropna().reset_index(drop=True)\n",
        "\n",
        "        # 2. Минимальная предобработка (как в вашем коде):\n",
        "        data = data[['Skills', 'From', 'To']].rename(columns={'From': 'from', 'To': 'to'})\n",
        "        # Убираем строки, где from == to\n",
        "        data = data[data['from'] != data['to']]\n",
        "        # Убираем строки, где Skills пуст\n",
        "        data = data[data['Skills'].apply(len) > 0]\n",
        "\n",
        "        if len(data) == 0:\n",
        "            # Если для этой области данных нет, создаём пустой словарь\n",
        "            skill_dict[area] = {}\n",
        "            continue\n",
        "\n",
        "        # 3. Собираем список всех навыков\n",
        "        all_skills = get_all_skills(data)\n",
        "\n",
        "        # 4. Создаём словарь маппинга навыка -> индекс\n",
        "        skill_id_dict = {skill: idx for idx, skill in enumerate(all_skills)}\n",
        "\n",
        "        # 5. Собираем матрицу A\n",
        "        A = get_matrix(data, skill_id_dict)\n",
        "\n",
        "        # 6. Оптимизатор возвращает вектор x — стоимости навыков\n",
        "        # (final_interval_loss, mae можно сохранить при необходимости)\n",
        "        x, final_interval_loss, mae = calc_torch_interval(\n",
        "            A,\n",
        "            data['from'].values,\n",
        "            data['to'].values,\n",
        "            lr=5,\n",
        "            num_iterations=50000\n",
        "        )\n",
        "\n",
        "        # 7. Формируем словарь навыков и их стоимости для данной области\n",
        "        area_skills = {}\n",
        "        for skill, idx in skill_id_dict.items():\n",
        "            # x[idx] может быть тензором или numpy.float;\n",
        "            # приводим к float для удобства\n",
        "            area_skills[skill] = float(x[idx])\n",
        "\n",
        "        # 8. Сохраняем результат в общий словарь\n",
        "        skill_dict[area] = area_skills\n",
        "\n",
        "    return skill_dict\n",
        "\n",
        "\n",
        "\n",
        "# Собираем большой словарь с навыками и их стоимостью для всех областей\n",
        "skill_dict = build_skill_dict(vacancies, prof_areas)\n",
        "\n",
        "# Теперь в result_skill_dict у вас пять ключей (пять профессиональных областей),\n",
        "# в каждом — вложенный словарь \"навык\" -> \"стоимость\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6Bi0NrwuAp7",
        "outputId": "b10ee8cb-6d12-4879-f5d3-d64b2fe100e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skill_dict.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aU_XVO7UF53V",
        "outputId": "cf79d395-f403-43ea-92b6-73b5ba31be14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['Информационные технологии, интернет, телеком', 'Закупки', 'Административный персонал', 'Добыча сырья', 'Высший менеджмент', 'Страхование', 'Консультирование', 'Продажи', 'Безопасность', 'Юристы', 'Рабочий персонал', 'Маркетинг, реклама, PR', 'Наука, образование', 'Транспорт, логистика', 'Банки, инвестиции, лизинг', 'Туризм, гостиницы, рестораны', 'Домашний персонал', 'Медицина, фармацевтика', 'Производство, сельское хозяйство', 'Инсталляция и сервис', 'Спортивные клубы, фитнес, салоны красоты', 'Автомобильный бизнес', 'Строительство, недвижимость', 'Начало карьеры, студенты', 'Государственная служба, некоммерческие организации', 'Искусство, развлечения, масс-медиа', 'Управление персоналом, тренинги', 'Бухгалтерия, управленческий учет, финансы предприятия'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BPzcsrhtvFFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_skill_dict_to_json(skill_dict, filename=\"/content/drive/MyDrive/Colab Notebooks/cost_of_skills/skill_dict.json\"):\n",
        "    \"\"\"\n",
        "    Saves the given skill_dict to a JSON file.\n",
        "\n",
        "    :param skill_dict: Dictionary of professional areas\n",
        "                       and their corresponding skills and costs.\n",
        "    :param filename: The name of the JSON file to save.\n",
        "    \"\"\"\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        # ensure_ascii=False allows saving Cyrillic (and other non-ASCII) characters properly\n",
        "        json.dump(skill_dict, f, ensure_ascii=False, indent=2)\n",
        "    print(f\"Skill dictionary saved to {filename}\")"
      ],
      "metadata": {
        "id": "tzHGsKXrurmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_skill_dict_to_json(skill_dict, \"/content/drive/MyDrive/Colab Notebooks/cost_of_skills/my_skill_dict.json\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4-9S28euuVk",
        "outputId": "0e7e5fcb-7a61-42ea-b51d-6e57c896eb63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Skill dictionary saved to /content/drive/MyDrive/Colab Notebooks/cost_of_skills/my_skill_dict.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BhbeY3MtvF-k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gradio run"
      ],
      "metadata": {
        "id": "egRg6gVDfmtH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/drive/MyDrive/Colab Notebooks/cost_of_skills/my_skill_dict_cleaned_v2.json\", \"r\", encoding=\"utf-8\") as f:\n",
        "        skill_dict = json.load(f)\n"
      ],
      "metadata": {
        "id": "WVOCjv87vF7I"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_skills(selected_profession):\n",
        "    \"\"\"\n",
        "    Функция вызывается при выборе профессиональной области,\n",
        "    чтобы обновить список навыков в чекбоксах.\n",
        "    \"\"\"\n",
        "    if selected_profession in skill_dict:\n",
        "        new_choices = list(skill_dict[selected_profession].keys())\n",
        "    else:\n",
        "        new_choices = []\n",
        "    return gr.update(choices=new_choices, value=[])\n",
        "\n",
        "def calculate_skills(selected_profession, selected_skills):\n",
        "    \"\"\"\n",
        "    Функция расчёта стоимости выбранных навыков.\n",
        "    Возвращает DataFrame с названием навыка и его стоимостью.\n",
        "    В конце добавляется строка с суммарной стоимостью.\n",
        "    \"\"\"\n",
        "    # Если пользователь не выбрал профессию или навыки\n",
        "    if not selected_profession or not selected_skills:\n",
        "        return pd.DataFrame(columns=[\"Навык\", \"Стоимость\"])\n",
        "\n",
        "    # Берём словарь навыков для выбранной профессии\n",
        "    skills_for_profession = skill_dict.get(selected_profession, {})\n",
        "\n",
        "    # Формируем данные только по выбранным навыкам\n",
        "    selected_data = {skill: skills_for_profession[skill] for skill in selected_skills}\n",
        "\n",
        "    df = pd.DataFrame(selected_data.items(), columns=[\"Навык\", \"Стоимость\"])\n",
        "    total_cost = df[\"Стоимость\"].sum()\n",
        "    df.loc[len(df)] = [\"Суммарная стоимость\", total_cost]\n",
        "    return df"
      ],
      "metadata": {
        "id": "nQPpXoqSveyJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## Калькулятор стоимости навыков\")\n",
        "\n",
        "    # Выбор профессиональной области\n",
        "    profession_dropdown = gr.Dropdown(\n",
        "        choices=list(skill_dict.keys()),\n",
        "        label=\"Выберите профессиональную область\",\n",
        "        value=None,\n",
        "        interactive=True\n",
        "    )\n",
        "\n",
        "    # Чекбоксы для навыков (изначально пустые — заполняются при смене области)\n",
        "    skills_checkbox = gr.CheckboxGroup(\n",
        "        choices=[],\n",
        "        label=\"Выберите навыки\",\n",
        "        value=[],\n",
        "        interactive=True\n",
        "    )\n",
        "\n",
        "    # Кнопка для расчёта\n",
        "    calc_button = gr.Button(\"Рассчитать стоимость\")\n",
        "\n",
        "    # Таблица результата\n",
        "    result_table = gr.Dataframe(\n",
        "        label=\"Таблица стоимости\",\n",
        "        headers=[\"Навык\", \"Стоимость\"],\n",
        "        interactive=False\n",
        "    )\n",
        "\n",
        "    # Обновление списка навыков при смене профессиональной области\n",
        "    profession_dropdown.change(\n",
        "        fn=update_skills,\n",
        "        inputs=profession_dropdown,\n",
        "        outputs=skills_checkbox\n",
        "    )\n",
        "\n",
        "    # Нажатие кнопки вызывает функцию calculate_skills\n",
        "    calc_button.click(\n",
        "        fn=calculate_skills,\n",
        "        inputs=[profession_dropdown, skills_checkbox],\n",
        "        outputs=result_table\n",
        "    )\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "lI9GDtD3lmSC",
        "outputId": "a6d0b37e-36be-4fc1-871d-b718a5397540"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://aca74b6749733601c4.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://aca74b6749733601c4.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}